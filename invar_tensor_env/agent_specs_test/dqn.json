{
    "type": "dqn_agent",

    "memory": {
        "type": "prioritized_replay",
        "capacity": 10000,
        "include_next_states": true
    },

    "discount": 0.99,

    "actions_exploration": {
        "type": "epsilon_anneal",
        "initial_epsilon": 0.5,
        "final_epsilon": 0.05,
        "timesteps": 5000
    }
}
